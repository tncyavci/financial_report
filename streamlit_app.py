"""
Turkish Financial RAG Chatbot
Streamlit Aray√ºz√º - A100 GPU Optimized
"""

import streamlit as st
import os
import logging
import asyncio
from pathlib import Path
import tempfile
import time
from typing import List, Dict, Optional

# Logging konfig√ºrasyonu
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Page config
st.set_page_config(
    page_title="Turkish Financial RAG Assistant",
    page_icon="üí∞",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    
    .subheader {
        font-size: 1.5rem;
        color: #2c3e50;
        margin-bottom: 1rem;
        border-bottom: 2px solid #3498db;
        padding-bottom: 0.5rem;
    }
    
    .stat-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    
    .success-message {
        background: linear-gradient(90deg, #00b09b, #96c93d);
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    
    .error-message {
        background: linear-gradient(90deg, #ff6b6b, #ee5a24);
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .user-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        margin-left: 2rem;
    }
    
    .assistant-message {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
        margin-right: 2rem;
    }
    
    .sidebar-content {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Ba≈ülƒ±k
st.markdown('<div class="main-header">üí∞ Turkish Financial RAG Assistant</div>', unsafe_allow_html=True)
st.markdown('<p style="text-align: center; color: #7f8c8d; font-size: 1.2rem;">A100 GPU ile Optimize Edilmi≈ü T√ºrk√ße Finans D√∂k√ºman Analizi</p>', unsafe_allow_html=True)

# Session state initialization
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'retrieval_service' not in st.session_state:
    st.session_state.retrieval_service = None
if 'llm_service' not in st.session_state:
    st.session_state.llm_service = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'processed_files' not in st.session_state:
    st.session_state.processed_files = []
if 'system_initialized' not in st.session_state:
    st.session_state.system_initialized = False

def initialize_system():
    """Sistemi ba≈ülat"""
    try:
        with st.spinner("üöÄ Sistem ba≈ülatƒ±lƒ±yor..."):
            # Import statements
            from src.text_processor import EmbeddingService
            from src.vector_store import VectorStore, RetrievalService
            from src.llm_service_local import GGUFModelService
            
            # Embedding servisini ba≈ülat
            if 'embedding_service' not in st.session_state:
                st.session_state.embedding_service = EmbeddingService()
                logger.info("‚úÖ Embedding service ba≈ülatƒ±ldƒ±")
            
            # Vector store ba≈ülat
            if st.session_state.vector_store is None:
                st.session_state.vector_store = VectorStore(persist_directory="./chroma_db")
                logger.info("‚úÖ Vector store ba≈ülatƒ±ldƒ±")
            
            # Retrieval service ba≈ülat
            if st.session_state.retrieval_service is None:
                st.session_state.retrieval_service = RetrievalService(
                    st.session_state.vector_store, 
                    st.session_state.embedding_service
                )
                logger.info("‚úÖ Retrieval service ba≈ülatƒ±ldƒ±")
            
            # LLM service ba≈ülat
            if st.session_state.llm_service is None:
                model_path = "/content/drive/MyDrive/Colab Notebooks/kredi_rag_sistemi/backup/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf"
                
                # Colab ortamƒ± kontrol
                if os.path.exists(model_path):
                    st.session_state.llm_service = GGUFModelService(model_path=model_path)
                    logger.info("‚úÖ GGUF LLM service ba≈ülatƒ±ldƒ±")
                else:
                    st.warning("‚ö†Ô∏è Model dosyasƒ± bulunamadƒ±. HuggingFace modeli kullanƒ±lacak.")
                    from src.llm_service_local import HuggingFaceModelService
                    st.session_state.llm_service = HuggingFaceModelService()
                    logger.info("‚úÖ HuggingFace LLM service ba≈ülatƒ±ldƒ±")
            
            st.session_state.system_initialized = True
            return True
            
    except Exception as e:
        st.error(f"‚ùå Sistem ba≈ülatma hatasƒ±: {e}")
        logger.error(f"System initialization error: {e}")
        return False

def process_uploaded_files(uploaded_files):
    """Y√ºklenen dosyalarƒ± i≈üle"""
    try:
        from src.pdf_processor import PDFProcessor
        from src.excel_processor import ExcelProcessor
        from src.text_processor import TextProcessor
        
        pdf_processor = PDFProcessor()
        excel_processor = ExcelProcessor()
        text_processor = TextProcessor()
        
        all_chunks = []
        processed_info = []
        
        for uploaded_file in uploaded_files:
            with st.spinner(f"üìÑ {uploaded_file.name} i≈üleniyor..."):
                # Ge√ßici dosya olu≈ütur
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_path = tmp_file.name
                
                try:
                    file_chunks = []
                    
                    # Dosya t√ºr√ºne g√∂re i≈üle
                    if uploaded_file.name.lower().endswith('.pdf'):
                        # PDF i≈üleme
                        pdf_content = pdf_processor.extract_content(tmp_path)
                        
                        for page_num, page_data in pdf_content.items():
                            # Text chunks
                            if page_data.get('text'):
                                chunks = text_processor.create_chunks(
                                    page_data['text'],
                                    source_file=uploaded_file.name,
                                    page_number=page_num,
                                    content_type='text'
                                )
                                file_chunks.extend(chunks)
                            
                            # Table chunks
                            if page_data.get('tables'):
                                for table_idx, table in enumerate(page_data['tables']):
                                    table_text = table.get('text', '')
                                    if table_text:
                                        chunks = text_processor.create_chunks(
                                            table_text,
                                            source_file=uploaded_file.name,
                                            page_number=page_num,
                                            content_type='table',
                                            metadata={'table_index': table_idx}
                                        )
                                        file_chunks.extend(chunks)
                    
                    elif uploaded_file.name.lower().endswith(('.xlsx', '.xls', '.xlsm')):
                        # Excel i≈üleme
                        excel_content = excel_processor.extract_content(tmp_path)
                        
                        for sheet_name, sheet_data in excel_content.items():
                            if sheet_data.get('text'):
                                chunks = text_processor.create_chunks(
                                    sheet_data['text'],
                                    source_file=uploaded_file.name,
                                    page_number=1,  # Excel i√ßin sheet index
                                    content_type='table',
                                    metadata={'sheet_name': sheet_name}
                                )
                                file_chunks.extend(chunks)
                    
                    # Embeddings olu≈ütur
                    if file_chunks:
                        st.session_state.embedding_service.embed_chunks(file_chunks)
                        all_chunks.extend(file_chunks)
                        
                        processed_info.append({
                            'filename': uploaded_file.name,
                            'chunks': len(file_chunks),
                            'size': len(uploaded_file.getvalue()),
                            'type': uploaded_file.name.split('.')[-1].upper()
                        })
                
                finally:
                    # Ge√ßici dosyayƒ± sil
                    os.unlink(tmp_path)
        
        # Vector store'a ekle
        if all_chunks:
            st.session_state.vector_store.add_documents(all_chunks)
            st.session_state.processed_files.extend(processed_info)
            
            return len(all_chunks), processed_info
        else:
            return 0, []
            
    except Exception as e:
        st.error(f"‚ùå Dosya i≈üleme hatasƒ±: {e}")
        logger.error(f"File processing error: {e}")
        return 0, []

def generate_response(query: str) -> str:
    """Query i√ßin cevap √ºret"""
    try:
        # Context retrieve et
        retrieval_result = st.session_state.retrieval_service.retrieve_context(query, n_results=5)
        
        if not retrieval_result.results:
            return "‚ö†Ô∏è ƒ∞lgili bilgi bulunamadƒ±. L√ºtfen daha spesifik bir soru sorun veya ilgili d√∂k√ºmanlarƒ± y√ºklediƒüinizden emin olun."
        
        # LLM ile cevap √ºret
        response = st.session_state.llm_service.generate_response(
            query=query,
            context=retrieval_result.combined_context
        )
        
        return response
        
    except Exception as e:
        logger.error(f"Response generation error: {e}")
        return f"‚ùå Cevap √ºretme hatasƒ±: {str(e)}"

# Sidebar
with st.sidebar:
    st.markdown('<div class="subheader">üõ†Ô∏è Sistem Kontrolleri</div>', unsafe_allow_html=True)
    
    # Sistem ba≈ülatma
    if not st.session_state.system_initialized:
        if st.button("üöÄ Sistemi Ba≈ülat", type="primary"):
            if initialize_system():
                st.success("‚úÖ Sistem ba≈üarƒ±yla ba≈ülatƒ±ldƒ±!")
                st.rerun()
            else:
                st.error("‚ùå Sistem ba≈ülatƒ±lamadƒ±!")
    else:
        st.success("‚úÖ Sistem Aktif")
    
    # Dosya y√ºkleme
    if st.session_state.system_initialized:
        st.markdown('<div class="subheader">üìÅ Dosya Y√ºkleme</div>', unsafe_allow_html=True)
        
        uploaded_files = st.file_uploader(
            "PDF veya Excel dosyalarƒ±nƒ± y√ºkleyin",
            type=['pdf', 'xlsx', 'xls', 'xlsm'],
            accept_multiple_files=True,
            help="T√ºrk√ße finans d√∂k√ºmanlarƒ±nƒ± y√ºkleyebilirsiniz"
        )
        
        if uploaded_files and st.button("üìÑ Dosyalarƒ± ƒ∞≈üle"):
            chunk_count, processed_info = process_uploaded_files(uploaded_files)
            
            if chunk_count > 0:
                st.markdown(f'<div class="success-message">‚úÖ {chunk_count} chunk ba≈üarƒ±yla i≈ülendi!</div>', unsafe_allow_html=True)
                
                for info in processed_info:
                    st.write(f"üìÑ **{info['filename']}** ({info['type']}) - {info['chunks']} chunk")
            else:
                st.markdown('<div class="error-message">‚ùå Dosya i≈ülenemedi!</div>', unsafe_allow_html=True)
    
    # Sistem istatistikleri
    if st.session_state.system_initialized and st.session_state.retrieval_service:
        st.markdown('<div class="subheader">üìä Sistem ƒ∞statistikleri</div>', unsafe_allow_html=True)
        
        try:
            stats = st.session_state.retrieval_service.get_retrieval_stats()
            vector_stats = stats.get('vector_store_stats', {})
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("üìÑ Toplam Dok√ºman", vector_stats.get('total_documents', 0))
                st.metric("üóÇÔ∏è Kaynak Sayƒ±sƒ±", vector_stats.get('unique_sources', 0))
            
            with col2:
                st.metric("üí¨ Chat Ge√ßmi≈üi", len(st.session_state.chat_history))
                st.metric("üìÅ ƒ∞≈ülenen Dosya", len(st.session_state.processed_files))
            
            # ƒ∞√ßerik daƒüƒ±lƒ±mƒ±
            content_dist = vector_stats.get('content_type_distribution', {})
            if content_dist:
                st.write("**ƒ∞√ßerik T√ºr√º Daƒüƒ±lƒ±mƒ±:**")
                for content_type, count in content_dist.items():
                    st.write(f"‚Ä¢ {content_type}: {count}")
        
        except Exception as e:
            st.error(f"ƒ∞statistik hatasƒ±: {e}")
    
    # Sistem temizleme
    if st.session_state.system_initialized:
        st.markdown('<div class="subheader">üóëÔ∏è Sistem Temizleme</div>', unsafe_allow_html=True)
        
        if st.button("üóëÔ∏è Vector Store Temizle", type="secondary"):
            try:
                st.session_state.vector_store.clear()
                st.session_state.processed_files = []
                st.success("‚úÖ Vector store temizlendi!")
            except Exception as e:
                st.error(f"‚ùå Temizleme hatasƒ±: {e}")
        
        if st.button("üí¨ Chat Ge√ßmi≈üini Temizle", type="secondary"):
            st.session_state.chat_history = []
            st.success("‚úÖ Chat ge√ßmi≈üi temizlendi!")

# Ana i√ßerik
if not st.session_state.system_initialized:
    st.info("üëà L√ºtfen √∂nce sistemi ba≈ülatƒ±n")
else:
    # Chat aray√ºz√º
    st.markdown('<div class="subheader">üí¨ Chat Aray√ºz√º</div>', unsafe_allow_html=True)
    
    # Chat ge√ßmi≈üini g√∂ster
    chat_container = st.container()
    
    with chat_container:
        for i, (role, message) in enumerate(st.session_state.chat_history):
            if role == "user":
                st.markdown(f'<div class="chat-message user-message"><strong>üë§ Siz:</strong><br>{message}</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="chat-message assistant-message"><strong>ü§ñ Asistan:</strong><br>{message}</div>', unsafe_allow_html=True)
    
    # Yeni mesaj giri≈üi
    user_input = st.chat_input("T√ºrk√ße finans sorularƒ±nƒ±zƒ± sorun...")
    
    if user_input:
        # Kullanƒ±cƒ± mesajƒ±nƒ± ekle
        st.session_state.chat_history.append(("user", user_input))
        
        # Cevap √ºret
        with st.spinner("ü§î D√º≈ü√ºn√ºyor..."):
            response = generate_response(user_input)
        
        # Cevabƒ± ekle
        st.session_state.chat_history.append(("assistant", response))
        
        # Sayfayƒ± yenile
        st.rerun()
    
    # √ñrnek sorular
    if not st.session_state.chat_history:
        st.markdown('<div class="subheader">üí° √ñrnek Sorular</div>', unsafe_allow_html=True)
        
        example_questions = [
            "Bu d√∂k√ºmanlarƒ±n √∂zeti nedir?",
            "Finansal tablolardaki ana g√∂stergeler nelerdir?",
            "Risk analizinde √∂ne √ßƒ±kan fakt√∂rler neler?",
            "Gelir tablosundaki trend nasƒ±l?",
            "Nakit akƒ±mƒ± durumu nasƒ±l?"
        ]
        
        cols = st.columns(3)
        for i, question in enumerate(example_questions):
            with cols[i % 3]:
                if st.button(question, key=f"example_{i}"):
                    st.session_state.chat_history.append(("user", question))
                    with st.spinner("ü§î D√º≈ü√ºn√ºyor..."):
                        response = generate_response(question)
                    st.session_state.chat_history.append(("assistant", response))
                    st.rerun()
    
    # Footer
    st.markdown("---")
    st.markdown(
        '<p style="text-align: center; color: #95a5a6;">Turkish Financial RAG Assistant | A100 GPU Optimized | ChromaDB + Mistral 7B</p>',
        unsafe_allow_html=True
    ) 