# ğŸš€ Google Colab Evaluation Guide

Turkish Financial RAG System - Evaluation modÃ¼lÃ¼nÃ¼ Google Colab'da Ã§alÄ±ÅŸtÄ±rma kÄ±lavuzu

## ğŸ“‹ **HazÄ±rlÄ±k (5 dakika)**

### **1. NGROK HesabÄ± OluÅŸturun**
1. https://ngrok.com/ adresine gidin
2. Ãœcretsiz hesap oluÅŸturun
3. Dashboard'dan **auth token**'inizi kopyalayÄ±n

## ğŸš€ **Colab'da Ã‡alÄ±ÅŸtÄ±rma**

### **YÃ¶ntem 1: HÄ±zlÄ± Test (Sadece Performance)**

```python
# Cell 1: Repository klonla
!git clone https://github.com/your-username/financial_report.git
%cd financial_report
```

```python
# Cell 2: HÄ±zlÄ± performance test
!PYTHONPATH=/content/financial_report python evaluation/test_performance.py
```

### **YÃ¶ntem 2: Full Evaluation (Performance + Accuracy)**

#### **Cell 1: Setup**
```python
# Repository klonla ve setup
!git clone https://github.com/your-username/financial_report.git
%cd financial_report

# System bilgilerini kontrol et
import sys
print(f"Python: {sys.version}")
print(f"Working Directory: {os.getcwd()}")

try:
    import torch
    print(f"PyTorch: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
except:
    print("PyTorch not available")
```

#### **Cell 2: Dependencies**
```python
# Requirements install
!pip install streamlit pandas psutil pyngrok -q

# Python path setup
import sys
import os
sys.path.append('/content/financial_report')

print("âœ… Dependencies installed!")
```

#### **Cell 3: Test Queries Generate**
```python
# Test queries oluÅŸtur
!PYTHONPATH=/content/financial_report python evaluation/test_query_generator.py

# DosyalarÄ± kontrol et
!ls -la evaluation/data/
!ls -la evaluation/reports/
```

#### **Cell 4: NGROK Setup**
```python
# NGROK token'inizi buraya girin
from pyngrok import ngrok

# Token'inizi buraya yazÄ±n
NGROK_TOKEN = "YOUR_NGROK_TOKEN_HERE"  # https://ngrok.com/

ngrok.set_auth_token(NGROK_TOKEN)
print("âœ… NGROK configured!")
```

#### **Cell 5: Streamlit App Ã‡alÄ±ÅŸtÄ±r**
```python
# Enhanced Streamlit app baÅŸlat
import subprocess
import threading
import time
from pyngrok import ngrok

def run_streamlit():
    subprocess.run([
        sys.executable, "-m", "streamlit", "run",
        "evaluation/streamlit_accuracy_app.py",  # Enhanced app
        "--server.port", "8501",
        "--server.headless", "true",
        "--server.enableCORS", "false",
        "--server.enableXsrfProtection", "false"
    ])

# Streamlit'i background'da baÅŸlat
thread = threading.Thread(target=run_streamlit)
thread.daemon = True
thread.start()

# BaÅŸlamasÄ±nÄ± bekle
print("â³ Starting Streamlit...")
time.sleep(15)

# NGROK tunnel oluÅŸtur
print("ğŸŒ Creating public tunnel...")
public_url = ngrok.connect(8501)

print(f"\nğŸ‰ SUCCESS! Your app is ready:")
print(f"ğŸ”— {public_url}")
print(f"\nğŸ“Š Available Features:")
print(f"   âš¡ Performance Testing")
print(f"   ğŸ¯ Accuracy Evaluation (31 test queries)")
print(f"   ğŸ“ˆ Analytics Dashboard")
print(f"   ğŸ§ª Test Query Management")
```

### **YÃ¶ntem 3: Otomatik Setup**

#### **Single Cell Run:**
```python
# Tek hÃ¼crede tÃ¼m setup
!git clone https://github.com/your-username/financial_report.git
%cd financial_report

# HÄ±zlÄ± setup Ã§alÄ±ÅŸtÄ±r
!python evaluation/colab_launcher.py

# Token girin
from pyngrok import ngrok
ngrok.set_auth_token("YOUR_TOKEN_HERE")

# Enhanced app Ã§alÄ±ÅŸtÄ±r
!PYTHONPATH=/content/financial_report python evaluation/colab_test_setup.py
```

## ğŸ¯ **App KullanÄ±mÄ±**

### **ğŸ“Š 4 Ana Sayfa:**

#### **1. ğŸš€ Performance Testing**
- PDF processing simulation
- Query response timing
- System resource monitoring
- Real-time performance metrics

#### **2. ğŸ“Š Accuracy Evaluation**
- 31 test query'den birini seÃ§
- "Generate RAG Response" tÄ±kla
- Manuel evaluation (1-5 scale)
- Success/failure tracking

#### **3. ğŸ“ˆ Analytics Dashboard**
- Combined performance + accuracy metrics
- Category-based analysis
- Downloadable reports

#### **4. ğŸ§ª Test Queries**
- 31 test query gÃ¶rÃ¼ntÃ¼le
- Yeni query'ler ekle
- Quick evaluation

### **ğŸ”„ Manuel Evaluation Workflow:**

1. **Test Queries sayfasÄ±na git**
2. **"Generate 30 Test Queries" tÄ±kla**
3. **Accuracy Evaluation sayfasÄ±na geÃ§**
4. **Query seÃ§ ve "Generate RAG Response" tÄ±kla**
5. **1-5 scale ile score ver:**
   - 5 = EXCELLENT (MÃ¼kemmel)
   - 4 = GOOD (Ä°yi)
   - 3 = FAIR (Orta) - Success threshold
   - 2 = POOR (ZayÄ±f)
   - 1 = FAILED (BaÅŸarÄ±sÄ±z)
6. **"Submit Evaluation" tÄ±kla**
7. **Analytics'de sonuÃ§larÄ± gÃ¶r**

## ğŸ“Š **Expected Results**

### **Performance Metrics:**
- PDF Processing: 1-3 seconds
- Query Response: 0.5-2 seconds
- Embedding Generation: 0.2-1.5 seconds

### **Accuracy Metrics:**
- Success Rate: 70-85%
- Average Quality: 3.5-4.2/5
- Category breakdown by financial domain

## ğŸ› ï¸ **Troubleshooting**

### **âŒ NGROK Error:**
```python
# Token'i yeniden set edin
from pyngrok import ngrok
ngrok.kill()
ngrok.set_auth_token("YOUR_TOKEN")
```

### **âŒ Import Error:**
```python
# Path'i manuel ekleyin
import sys
sys.path.append('/content/financial_report')
```

### **âŒ Port Conflict:**
```python
# Mevcut process'leri kill edin
!pkill -f streamlit
!pkill -f ngrok
```

### **âŒ Streamlit Not Starting:**
```python
# Manuel baÅŸlatma
!PYTHONPATH=/content/financial_report streamlit run evaluation/streamlit_accuracy_app.py --server.port 8502
```

## ğŸ“ˆ **Academic Usage**

### **Performance Analysis:**
```python
# Performance data al
from evaluation.metrics.performance_tracker import get_global_tracker
tracker = get_global_tracker()
summary = tracker.get_performance_summary()
print(f"Average response time: {summary['duration_stats']['avg']:.2f}s")
```

### **Accuracy Analysis:**
```python
# Accuracy data al
from evaluation.metrics.accuracy_tracker import get_global_accuracy_tracker
acc_tracker = get_global_accuracy_tracker()
metrics = acc_tracker.get_accuracy_metrics()
print(f"Success rate: {metrics.success_rate:.1f}%")
print(f"Average quality: {metrics.average_quality_score:.2f}/5")
```

### **Combined Report:**
```python
# Akademik rapor oluÅŸtur
report = acc_tracker.generate_test_report()
print(report)

# Download iÃ§in
with open('evaluation_report.md', 'w') as f:
    f.write(report)
```

## ğŸ’¾ **Data Export**

### **JSON Download:**
- Performance metrics: `performance_metrics.json`
- Accuracy metrics: `accuracy_metrics.json`
- Test queries: `test_queries.json`

### **Academic Papers:**
```python
# Publication-ready data
data = {
    "performance": tracker.get_performance_summary(),
    "accuracy": acc_tracker.get_accuracy_metrics(),
    "methodology": "Manual evaluation of 31 financial queries",
    "scoring_system": "5-point Likert scale",
    "success_threshold": "Score >= 3"
}

import json
with open('academic_data.json', 'w') as f:
    json.dump(data, f, indent=2, default=str)
```

## ğŸ¯ **Next Steps**

1. **Test 10-15 query** ile baÅŸlayÄ±n
2. **Success rate patterns** analiz edin
3. **Category performance** inceleyin
4. **Academic paper** iÃ§in data toplayÄ±n

**âœ… Bu guide ile Colab'da full evaluation sisteminizi Ã§alÄ±ÅŸtÄ±rabilir ve 31 test query ile comprehensive accuracy analysis yapabilirsiniz!** 