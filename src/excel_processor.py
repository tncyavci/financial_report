"""
Excel ƒ∞≈üleme Mod√ºl√º
Excel dosyalarƒ±nƒ± okuma ve analiz etme i√ßin optimize edilmi≈ü
"""

import logging
import pandas as pd
import numpy as np
from typing import List, Dict, Optional, Any, Tuple
from dataclasses import dataclass
import openpyxl
from openpyxl import load_workbook
import xlrd
import os
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)

@dataclass
class SheetData:
    """Excel sayfa verisi container'ƒ±"""
    sheet_name: str
    text_content: str
    raw_data: pd.DataFrame
    summary_stats: Dict
    metadata: Dict

@dataclass
class ExcelResult:
    """Excel i≈üleme sonucu"""
    sheets: List[SheetData]
    total_sheets: int
    metadata: Dict

class ExcelProcessor:
    """
    Excel dosyalarƒ± i√ßin optimize edilmi≈ü i≈ülemci
    XLS, XLSX, XLSM formatlarƒ±nƒ± destekler
    Multiprocessing desteƒüi ile sheet paralel i≈üleme
    """
    
    def __init__(self, max_workers: int = None, use_multiprocessing: bool = True):
        """
        Excel i≈ülemci ba≈ülatƒ±cƒ±
        
        Args:
            max_workers: Paralel i≈ülem i√ßin maksimum worker sayƒ±sƒ±
            use_multiprocessing: Multiprocessing kullanƒ±lƒ±p kullanƒ±lmayacaƒüƒ±
        """
        self.max_workers = max_workers or min(4, os.cpu_count())
        self.use_multiprocessing = use_multiprocessing
        logger.info(f"üìä ExcelProcessor ba≈ülatƒ±ldƒ± - {self.max_workers} worker, MP: {use_multiprocessing}")
    
    def process_excel(self, excel_path: str) -> ExcelResult:
        """
        Excel dosyasƒ±nƒ± i≈üle ve sonu√ßlarƒ± d√∂nd√ºr
        
        Args:
            excel_path: Excel dosyasƒ±nƒ±n yolu
            
        Returns:
            ExcelResult: ƒ∞≈ülenmi≈ü Excel verisi
        """
        logger.info(f"üìä Excel i≈üleniyor: {excel_path}")
        
        try:
            # Dosya formatƒ±nƒ± belirle
            file_extension = os.path.splitext(excel_path)[1].lower()
            
            # Excel metadata'sƒ±nƒ± al
            excel_metadata = self._get_excel_metadata(excel_path, file_extension)
            
            # Sayfalarƒ± i≈üle (paralel veya sƒ±ralƒ±)
            sheets = self._process_all_sheets(excel_path, file_extension)
            
            result = ExcelResult(
                sheets=sheets,
                total_sheets=len(sheets),
                metadata=excel_metadata
            )
            
            logger.info(f"‚úÖ Excel i≈ülendi - {len(sheets)} sayfa")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Excel i≈üleme hatasƒ±: {e}")
            raise
    
    def _get_excel_metadata(self, excel_path: str, file_extension: str) -> Dict:
        """Excel metadata'sƒ±nƒ± √ßƒ±kar"""
        try:
            metadata = {
                'file_format': file_extension,
                'file_size': os.path.getsize(excel_path),
            }
            
            if file_extension in ['.xlsx', '.xlsm']:
                # openpyxl ile metadata al
                try:
                    wb = load_workbook(excel_path, read_only=True)
                    metadata.update({
                        'sheet_names': wb.sheetnames,
                        'sheet_count': len(wb.sheetnames),
                        'created': str(wb.properties.created) if wb.properties.created else '',
                        'modified': str(wb.properties.modified) if wb.properties.modified else '',
                        'creator': wb.properties.creator or '',
                        'title': wb.properties.title or ''
                    })
                    wb.close()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è openpyxl metadata alƒ±namadƒ±: {e}")
            
            elif file_extension == '.xls':
                # xlrd ile metadata al
                try:
                    with xlrd.open_workbook(excel_path) as wb:
                        metadata.update({
                            'sheet_names': wb.sheet_names(),
                            'sheet_count': wb.nsheets
                        })
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è xlrd metadata alƒ±namadƒ±: {e}")
            
            return metadata
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Excel metadata alƒ±namadƒ±: {e}")
            return {'file_format': file_extension}
    
    def _process_all_sheets(self, excel_path: str, file_extension: str) -> List[SheetData]:
        """T√ºm sayfalarƒ± i≈üle (paralel veya sƒ±ralƒ±)"""
        sheets = []
        
        try:
            # Pandas ile t√ºm sayfalarƒ± oku
            if file_extension == '.xls':
                # xlrd engine kullan
                all_sheets = pd.read_excel(excel_path, sheet_name=None, engine='xlrd')
            else:
                # openpyxl engine kullan
                all_sheets = pd.read_excel(excel_path, sheet_name=None, engine='openpyxl')
            
            sheet_count = len(all_sheets)
            logger.info(f"üìä {sheet_count} sayfa bulundu")
            
            # Paralel i≈üleme kararƒ±
            if sheet_count <= 2 or not self.use_multiprocessing:
                # K√º√ß√ºk Excel dosyalarƒ± i√ßin sƒ±ralƒ± i≈üleme
                logger.info("üìÑ K√º√ß√ºk Excel - sƒ±ralƒ± i≈üleme")
                for sheet_name, df in all_sheets.items():
                    logger.debug(f"üìÑ ƒ∞≈üleniyor: {sheet_name}")
                    sheet_data = self._process_single_sheet(sheet_name, df)
                    if sheet_data:
                        sheets.append(sheet_data)
            else:
                # B√ºy√ºk Excel dosyalarƒ± i√ßin paralel i≈üleme
                logger.info(f"üöÄ Paralel i≈üleme ba≈ülatƒ±lƒ±yor - {self.max_workers} worker")
                sheets = self._process_sheets_parallel(all_sheets)
            
            logger.info(f"‚úÖ {len(sheets)} sayfa ba≈üarƒ±yla i≈ülendi")
            
        except Exception as e:
            logger.error(f"‚ùå Sayfalar i≈ülenemedi: {e}")
            raise
        
        return sheets
    
    def _process_sheets_parallel(self, all_sheets: Dict[str, pd.DataFrame]) -> List[SheetData]:
        """Sayfalarƒ± paralel olarak i≈üle"""
        sheets = []
        
        # ThreadPoolExecutor kullan (I/O bound operations i√ßin daha uygun)
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # T√ºm sayfalar i√ßin task'larƒ± ba≈ülat
            future_to_sheet = {
                executor.submit(self._process_single_sheet, sheet_name, df): sheet_name
                for sheet_name, df in all_sheets.items()
            }
            
            # Sonu√ßlarƒ± topla
            for future in as_completed(future_to_sheet):
                sheet_name = future_to_sheet[future]
                try:
                    sheet_data = future.result()
                    if sheet_data:
                        sheets.append(sheet_data)
                        logger.debug(f"‚úÖ Sayfa i≈ülendi: {sheet_name}")
                except Exception as e:
                    logger.error(f"‚ùå Sayfa i≈ülenemedi {sheet_name}: {e}")
        
        # Sheet ismine g√∂re sƒ±rala (orijinal sƒ±rayƒ± koru)
        original_order = list(all_sheets.keys())
        sheets.sort(key=lambda x: original_order.index(x.sheet_name) if x.sheet_name in original_order else 999)
        
        return sheets
    
    def _process_single_sheet(self, sheet_name: str, df: pd.DataFrame) -> Optional[SheetData]:
        """Tek bir sayfayƒ± i≈üle"""
        try:
            # Bo≈ü sayfa kontrol√º
            if df.empty:
                logger.debug(f"‚ö†Ô∏è Bo≈ü sayfa atlanƒ±yor: {sheet_name}")
                return None
            
            # Veriyi temizle
            cleaned_df = self._clean_dataframe(df)
            
            # √áok az veri varsa atla
            if cleaned_df.empty or (cleaned_df.shape[0] <= 1 and cleaned_df.shape[1] <= 1):
                logger.debug(f"‚ö†Ô∏è Yetersiz veri, sayfa atlanƒ±yor: {sheet_name}")
                return None
            
            # √ñzet istatistikleri hesapla
            summary_stats = self._calculate_summary_stats(cleaned_df)
            
            # Metin formatƒ±na √ßevir
            text_content = self._dataframe_to_text(cleaned_df, sheet_name)
            
            # Metadata olu≈ütur
            metadata = {
                'original_shape': df.shape,
                'cleaned_shape': cleaned_df.shape,
                'data_types': dict(cleaned_df.dtypes.astype(str)),
                'has_numeric_data': any(cleaned_df.select_dtypes(include=[np.number]).columns),
                'has_text_data': any(cleaned_df.select_dtypes(include=['object']).columns),
                'null_counts': dict(cleaned_df.isnull().sum()),
                'processing_method': 'pandas'
            }
            
            return SheetData(
                sheet_name=sheet_name,
                text_content=text_content,
                raw_data=cleaned_df,
                summary_stats=summary_stats,
                metadata=metadata
            )
            
        except Exception as e:
            logger.error(f"‚ùå Sayfa i≈ülenemedi {sheet_name}: {e}")
            return None
    
    def _clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """DataFrame'i temizle"""
        # Kopyasƒ±nƒ± al
        cleaned_df = df.copy()
        
        # Tamamen bo≈ü satƒ±r ve s√ºtunlarƒ± kaldƒ±r
        cleaned_df = cleaned_df.dropna(how='all').dropna(axis=1, how='all')
        
        # Index'i resetle
        cleaned_df = cleaned_df.reset_index(drop=True)
        
        # S√ºtun adlarƒ±nƒ± temizle
        if not cleaned_df.empty:
            # ƒ∞lk satƒ±rƒ± header olarak kullanmayƒ± dene
            if cleaned_df.iloc[0].notna().any():
                new_columns = []
                for i, col in enumerate(cleaned_df.columns):
                    if pd.isna(cleaned_df.iloc[0, i]):
                        new_columns.append(f"S√ºtun_{i+1}")
                    else:
                        new_columns.append(str(cleaned_df.iloc[0, i]))
                
                # Eƒüer yeni column adlarƒ± mantƒ±klƒ±ysa kullan
                if len(set(new_columns)) > len(new_columns) * 0.7:  # %70 unique olmalƒ±
                    cleaned_df.columns = new_columns
                    cleaned_df = cleaned_df.drop(cleaned_df.index[0]).reset_index(drop=True)
        
        return cleaned_df
    
    def _calculate_summary_stats(self, df: pd.DataFrame) -> Dict:
        """√ñzet istatistikleri hesapla"""
        stats = {
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'numeric_columns': [],
            'text_columns': [],
            'null_percentage': 0
        }
        
        try:
            # Sayƒ±sal s√ºtunlar
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            stats['numeric_columns'] = numeric_cols
            stats['total_numeric_columns'] = len(numeric_cols)
            
            # Metin s√ºtunlarƒ±
            text_cols = df.select_dtypes(include=['object']).columns.tolist()
            stats['text_columns'] = text_cols
            stats['total_text_columns'] = len(text_cols)
            
            # Bo≈ü h√ºcre y√ºzdesi
            total_cells = df.size
            null_cells = df.isnull().sum().sum()
            stats['null_percentage'] = (null_cells / total_cells * 100) if total_cells > 0 else 0
            
            # Sayƒ±sal s√ºtunlar i√ßin √∂zet
            if numeric_cols:
                numeric_summary = {}
                for col in numeric_cols:
                    try:
                        col_data = df[col].dropna()
                        if not col_data.empty:
                            numeric_summary[col] = {
                                'min': float(col_data.min()),
                                'max': float(col_data.max()),
                                'mean': float(col_data.mean()),
                                'sum': float(col_data.sum()),
                                'count': int(col_data.count())
                            }
                    except:
                        continue
                
                stats['numeric_summary'] = numeric_summary
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ƒ∞statistik hesaplanamadƒ±: {e}")
        
        return stats
    
    def _dataframe_to_text(self, df: pd.DataFrame, sheet_name: str) -> str:
        """DataFrame'i aranabilir metin formatƒ±na √ßevir"""
        try:
            text_content = f"EXCEL SAYFASI: {sheet_name}\n\n"
            
            # Temel bilgiler
            text_content += f"Satƒ±r sayƒ±sƒ±: {len(df)}\n"
            text_content += f"S√ºtun sayƒ±sƒ±: {len(df.columns)}\n"
            text_content += f"S√ºtun adlarƒ±: {', '.join(map(str, df.columns))}\n\n"
            
            # Veri √∂rnekleri (ilk 10 satƒ±r)
            text_content += "VERƒ∞ ƒ∞√áERƒ∞ƒûƒ∞:\n"
            sample_data = df.head(10)
            
            # S√ºtun bazƒ±nda veri
            for col in df.columns:
                text_content += f"\n{col}:\n"
                col_data = sample_data[col].dropna()
                if not col_data.empty:
                    values = col_data.astype(str).tolist()
                    text_content += ", ".join(values[:20])  # ƒ∞lk 20 deƒüer
                    if len(col_data) > 20:
                        text_content += f" ... (toplam {len(df[col].dropna())} deƒüer)"
                text_content += "\n"
            
            # Sayƒ±sal √∂zet
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                text_content += "\nSAYISAL √ñZET:\n"
                for col in numeric_cols:
                    col_data = df[col].dropna()
                    if not col_data.empty:
                        text_content += f"{col}: Min={col_data.min():.2f}, Max={col_data.max():.2f}, "
                        text_content += f"Ortalama={col_data.mean():.2f}, Toplam={col_data.sum():.2f}\n"
            
            # Tablo formatƒ± (k√º√ß√ºk tablolar i√ßin)
            if len(df) <= 20 and len(df.columns) <= 10:
                text_content += "\nTABLO FORMATI:\n"
                text_content += df.to_string(index=False, max_rows=20, max_cols=10)
                text_content += "\n"
            
            return text_content
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Metin d√∂n√º≈üt√ºrme hatasƒ±: {e}")
            return f"EXCEL SAYFASI: {sheet_name}\n[Metin d√∂n√º≈üt√ºrme hatasƒ±]"
    
    def get_excel_summary(self, excel_result: ExcelResult) -> Dict:
        """Excel dosyasƒ±nƒ±n genel √∂zetini √ßƒ±kar"""
        summary = {
            'total_sheets': excel_result.total_sheets,
            'total_rows': 0,
            'total_columns': 0,
            'total_numeric_columns': 0,
            'sheet_summaries': []
        }
        
        try:
            for sheet in excel_result.sheets:
                sheet_summary = {
                    'name': sheet.sheet_name,
                    'rows': sheet.summary_stats.get('total_rows', 0),
                    'columns': sheet.summary_stats.get('total_columns', 0),
                    'numeric_columns': sheet.summary_stats.get('total_numeric_columns', 0),
                    'has_data': len(sheet.text_content) > 100
                }
                
                summary['sheet_summaries'].append(sheet_summary)
                summary['total_rows'] += sheet_summary['rows']
                summary['total_columns'] += sheet_summary['columns']
                summary['total_numeric_columns'] += sheet_summary['numeric_columns']
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è √ñzet hesaplanamadƒ±: {e}")
        
        return summary
    
    def get_processor_stats(self) -> Dict:
        """ƒ∞≈ülemci istatistiklerini d√∂nd√ºr"""
        return {
            'processor_type': 'ExcelProcessor',
            'max_workers': self.max_workers,
            'use_multiprocessing': self.use_multiprocessing,
            'supported_formats': ['.xls', '.xlsx', '.xlsm'],
            'features': [
                'multi_sheet_processing',
                'parallel_sheet_processing',
                'numeric_analysis',
                'text_extraction',
                'summary_statistics',
                'data_cleaning',
                'thread_based_concurrency'
            ],
            'engines': ['pandas', 'openpyxl', 'xlrd'],
            'optimization': {
                'small_files': 'sequential_processing (‚â§2 sheets)',
                'large_files': 'parallel_processing (>2 sheets)',
                'concurrency_type': 'ThreadPoolExecutor'
            }
        } 